<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Vidya Mani</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Vidya Mani</description>
    <image>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/</guid>
      <description>I am a passionate and results-driven Senior Data Scientist with extensive experience in machine learning, computer vision, and natural language processing. I specialize in developing and deploying advanced AI-driven solutions to solve complex problems and drive business innovation. I am constantly exploring new technologies and methodologies to enhance my skills and stay at the forefront of the field.
Let&amp;rsquo;s Connect
LinkedIn: vidya-mani Medium: vidyamani Github: vidyasrimani Academic Backgroung and Professional Experience</description>
    </item>
    
    <item>
      <title>Architecting Large-Scale Search Solutions on GCP: A Technical Deep Dive</title>
      <link>http://localhost:1313/writings/ml-design-with-gcp-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/writings/ml-design-with-gcp-intro/</guid>
      <description>Preview Architecting Large-Scale Search Solutions on GCP: A Technical Deep Dive This multi-part blog series outlines the architecture of a large-scale search and ranking solution using Google Cloud Platform (GCP). We’ll cover each system component, from data ingestion to serving, focusing on scalability, performance, and machine learning integration. Each part will detail specific GCP services, design rationales, and implementation considerations.
Read writing</description>
    </item>
    
    <item>
      <title>Architecting Large-Scale Search Solutions on GCP: Part 1 - Overview</title>
      <link>http://localhost:1313/writings/ml-design-with-gcp-part1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/writings/ml-design-with-gcp-part1/</guid>
      <description>Preview Architecting Large-Scale Search Solutions on GCP: Overview In today’s data-driven world, building large-scale machine learning (ML) solutions that can handle massive amounts of information, provide real-time insights, and scale effortlessly is more crucial than ever. Google Cloud Platform (GCP) offers a robust suite of tools and services that enable it to architect such systems with relative ease.
Read writing</description>
    </item>
    
    <item>
      <title>Architecting Large-Scale Search Solutions on GCP: Part 2 — Data Ingestion and Storage</title>
      <link>http://localhost:1313/writings/ml-design-with-gcp-part2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/writings/ml-design-with-gcp-part2/</guid>
      <description>Preview Architecting Large-Scale Search Solutions on GCP: Part 2 — Data Ingestion and Storage This section will examine a large-scale search architecture’s data ingestion and storage components. We’ll focus on efficiently handling high-volume data ingestion and reliably storing it using Google Cloud Platform services.
Data Ingestion We need to ingest large volumes of data from various sources for our search solution. To handle different data update patterns, we’ll use a combination of batch and streaming ingestion.</description>
    </item>
    
    <item>
      <title>BERT Based Semantic Search</title>
      <link>http://localhost:1313/projects/acetylcholinesterase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/acetylcholinesterase/</guid>
      <description>Abstract Implemented a BERT-based semantic search engine to enhance the accuracy and relevance of search results by understanding contextual nuances in queries and documents.</description>
    </item>
    
    <item>
      <title>Image Captioning</title>
      <link>http://localhost:1313/projects/acetylcholinesterase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/acetylcholinesterase/</guid>
      <description>Abstract Built an automatic image captioning application by combining CNN and RNN architectures, enhancing computer vision tasks.
Read More</description>
    </item>
    
    <item>
      <title>Multimodal Image Search Using Transformer-Based Architectures</title>
      <link>http://localhost:1313/projects/acetylcholinesterase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/acetylcholinesterase/</guid>
      <description>Abstract An image search system using a multimodal large language model trained with CLIP to map text and images into a shared embedding space for accurate retrieval based on textual queries.
Watch Demo</description>
    </item>
    
    <item>
      <title>My 1st post</title>
      <link>http://localhost:1313/page/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/page/</guid>
      <description>Desc Text.</description>
    </item>
    
    <item>
      <title>Network Node Discovery</title>
      <link>http://localhost:1313/projects/acetylcholinesterase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/acetylcholinesterase/</guid>
      <description>Abstract Network connectivity discovery is an extensively studied area, and there are many interesting mechanisms such as ping, traceroute, DNS, address resolution protocol (ARP), and SNMP available to discover network elements and the connectivity among them. Traceroute is a computer network diagnostic tool for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.
Read More</description>
    </item>
    
    <item>
      <title>Object Tracking using SLAM</title>
      <link>http://localhost:1313/projects/acetylcholinesterase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/acetylcholinesterase/</guid>
      <description>Abstract Implemented SLAM to localize a robot and build an environmental map using sensor data.
Read More</description>
    </item>
    
    
    <item>
      <title>Semantic Search Using SOLR</title>
      <link>http://localhost:1313/projects/acetylcholinesterase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/acetylcholinesterase/</guid>
      <description>Abstract Implemented a semantic search engine on a News Corpus, which will produce enhanced search results based on semantics. This can be achieved using various natural language Processing features and techniques. This project has to use a keyword-based strategy.
Read More</description>
    </item>
    
    <item>
      <title>Turbocharging Python for Data Science with Numba</title>
      <link>http://localhost:1313/writings/numba-for-data-science/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/writings/numba-for-data-science/</guid>
      <description>Preview Turbocharging Python for Data Science with Numba Python is powerful for data science, but it can struggle with heavy computations. Numba, an open-source JIT compiler, accelerates Python code by converting it into efficient machine code with minimal effort. By simply adding a decorator, Numba can significantly boost performance, making it ideal for numerical computations, custom algorithms, and real-time data processing, all while maintaining Python&amp;rsquo;s ease of use.
In this article, you’ll learn how to use Numba with data science.</description>
    </item>
    
  </channel>
</rss>
