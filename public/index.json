[{"content":"I am a passionate and results-driven Senior Data Scientist with extensive experience in machine learning, computer vision, and natural language processing. I specialize in developing and deploying advanced AI-driven solutions to solve complex problems and drive business innovation. I am constantly exploring new technologies and methodologies to enhance my skills and stay at the forefront of the field.\nLet\u0026rsquo;s Connect\nLinkedIn: vidya-mani Medium: vidyamani Github: vidyasrimani Academic Backgroung and Professional Experience\nCMRIT: Bachelor\u0026rsquo;s in Computer Science SAP Labs: Software Developer - Java UT Dallas: Bachelor\u0026rsquo;s in Computer Science Ericsson: Data Scientist ","permalink":"http://localhost:1313/about/","summary":"I am a passionate and results-driven Senior Data Scientist with extensive experience in machine learning, computer vision, and natural language processing. I specialize in developing and deploying advanced AI-driven solutions to solve complex problems and drive business innovation. I am constantly exploring new technologies and methodologies to enhance my skills and stay at the forefront of the field.\nLet\u0026rsquo;s Connect\nLinkedIn: vidya-mani Medium: vidyamani Github: vidyasrimani Academic Backgroung and Professional Experience","title":"About"},{"content":"Preview Architecting Large-Scale Search Solutions on GCP: A Technical Deep Dive This multi-part blog series outlines the architecture of a large-scale search and ranking solution using Google Cloud Platform (GCP). We’ll cover each system component, from data ingestion to serving, focusing on scalability, performance, and machine learning integration. Each part will detail specific GCP services, design rationales, and implementation considerations.\nRead writing\n","permalink":"http://localhost:1313/writings/ml-design-with-gcp-intro/","summary":"Preview Architecting Large-Scale Search Solutions on GCP: A Technical Deep Dive This multi-part blog series outlines the architecture of a large-scale search and ranking solution using Google Cloud Platform (GCP). We’ll cover each system component, from data ingestion to serving, focusing on scalability, performance, and machine learning integration. Each part will detail specific GCP services, design rationales, and implementation considerations.\nRead writing","title":"Architecting Large-Scale Search Solutions on GCP: A Technical Deep Dive"},{"content":"Preview Architecting Large-Scale Search Solutions on GCP: Overview In today’s data-driven world, building large-scale machine learning (ML) solutions that can handle massive amounts of information, provide real-time insights, and scale effortlessly is more crucial than ever. Google Cloud Platform (GCP) offers a robust suite of tools and services that enable it to architect such systems with relative ease.\nRead writing\n","permalink":"http://localhost:1313/writings/ml-design-with-gcp-part1/","summary":"Preview Architecting Large-Scale Search Solutions on GCP: Overview In today’s data-driven world, building large-scale machine learning (ML) solutions that can handle massive amounts of information, provide real-time insights, and scale effortlessly is more crucial than ever. Google Cloud Platform (GCP) offers a robust suite of tools and services that enable it to architect such systems with relative ease.\nRead writing","title":"Architecting Large-Scale Search Solutions on GCP: Part 1 - Overview"},{"content":"Preview Architecting Large-Scale Search Solutions on GCP: Part 2 — Data Ingestion and Storage This section will examine a large-scale search architecture’s data ingestion and storage components. We’ll focus on efficiently handling high-volume data ingestion and reliably storing it using Google Cloud Platform services.\nData Ingestion We need to ingest large volumes of data from various sources for our search solution. To handle different data update patterns, we’ll use a combination of batch and streaming ingestion. Read writing\n","permalink":"http://localhost:1313/writings/ml-design-with-gcp-part2/","summary":"Preview Architecting Large-Scale Search Solutions on GCP: Part 2 — Data Ingestion and Storage This section will examine a large-scale search architecture’s data ingestion and storage components. We’ll focus on efficiently handling high-volume data ingestion and reliably storing it using Google Cloud Platform services.\nData Ingestion We need to ingest large volumes of data from various sources for our search solution. To handle different data update patterns, we’ll use a combination of batch and streaming ingestion.","title":"Architecting Large-Scale Search Solutions on GCP: Part 2 — Data Ingestion and Storage"},{"content":"Abstract Implemented a BERT-based semantic search engine to enhance the accuracy and relevance of search results by understanding contextual nuances in queries and documents.\n","permalink":"http://localhost:1313/projects/acetylcholinesterase/","summary":"Abstract Implemented a BERT-based semantic search engine to enhance the accuracy and relevance of search results by understanding contextual nuances in queries and documents.","title":"BERT Based Semantic Search"},{"content":"Abstract Built an automatic image captioning application by combining CNN and RNN architectures, enhancing computer vision tasks.\nRead More\n","permalink":"http://localhost:1313/projects/acetylcholinesterase/","summary":"Abstract Built an automatic image captioning application by combining CNN and RNN architectures, enhancing computer vision tasks.\nRead More","title":"Image Captioning"},{"content":"Abstract An image search system using a multimodal large language model trained with CLIP to map text and images into a shared embedding space for accurate retrieval based on textual queries.\nWatch Demo\n","permalink":"http://localhost:1313/projects/acetylcholinesterase/","summary":"Abstract An image search system using a multimodal large language model trained with CLIP to map text and images into a shared embedding space for accurate retrieval based on textual queries.\nWatch Demo","title":"Multimodal Image Search Using Transformer-Based Architectures"},{"content":"Abstract Network connectivity discovery is an extensively studied area, and there are many interesting mechanisms such as ping, traceroute, DNS, address resolution protocol (ARP), and SNMP available to discover network elements and the connectivity among them. Traceroute is a computer network diagnostic tool for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.\nRead More\n","permalink":"http://localhost:1313/projects/acetylcholinesterase/","summary":"Abstract Network connectivity discovery is an extensively studied area, and there are many interesting mechanisms such as ping, traceroute, DNS, address resolution protocol (ARP), and SNMP available to discover network elements and the connectivity among them. Traceroute is a computer network diagnostic tool for displaying the route (path) and measuring transit delays of packets across an Internet Protocol (IP) network.\nRead More","title":"Network Node Discovery"},{"content":"Abstract Implemented SLAM to localize a robot and build an environmental map using sensor data.\nRead More\n","permalink":"http://localhost:1313/projects/acetylcholinesterase/","summary":"Abstract Implemented SLAM to localize a robot and build an environmental map using sensor data.\nRead More","title":"Object Tracking using SLAM"},{"content":"Abstract Implemented a semantic search engine on a News Corpus, which will produce enhanced search results based on semantics. This can be achieved using various natural language Processing features and techniques. This project has to use a keyword-based strategy.\nRead More\n","permalink":"http://localhost:1313/projects/acetylcholinesterase/","summary":"Abstract Implemented a semantic search engine on a News Corpus, which will produce enhanced search results based on semantics. This can be achieved using various natural language Processing features and techniques. This project has to use a keyword-based strategy.\nRead More","title":"Semantic Search Using SOLR"},{"content":"Preview Turbocharging Python for Data Science with Numba Python is powerful for data science, but it can struggle with heavy computations. Numba, an open-source JIT compiler, accelerates Python code by converting it into efficient machine code with minimal effort. By simply adding a decorator, Numba can significantly boost performance, making it ideal for numerical computations, custom algorithms, and real-time data processing, all while maintaining Python\u0026rsquo;s ease of use.\nIn this article, you’ll learn how to use Numba with data science.\nLet’s dive in!\nRead writing\n","permalink":"http://localhost:1313/writings/numba-for-data-science/","summary":"Preview Turbocharging Python for Data Science with Numba Python is powerful for data science, but it can struggle with heavy computations. Numba, an open-source JIT compiler, accelerates Python code by converting it into efficient machine code with minimal effort. By simply adding a decorator, Numba can significantly boost performance, making it ideal for numerical computations, custom algorithms, and real-time data processing, all while maintaining Python\u0026rsquo;s ease of use.\nIn this article, you’ll learn how to use Numba with data science.","title":"Turbocharging Python for Data Science with Numba"}]